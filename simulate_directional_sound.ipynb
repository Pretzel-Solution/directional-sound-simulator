{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simulate_directional_sound.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1EU3f_86rV_cmLV-lcA5EvYVbh6SbCglI",
      "authorship_tag": "ABX9TyMltY62OGerGmk6lpfb4jd0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pretzel-Solution/directional-sound-simulator/blob/master/simulate_directional_sound.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBPpRA0u-pwX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "86ea4392-8026-4df8-f0a7-295e53e5696b"
      },
      "source": [
        "!pip install sofasonix\n",
        "# press \"Mount Drive\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sofasonix in /usr/local/lib/python3.6/dist-packages (1.0.6)\n",
            "Requirement already satisfied: netCDF4 in /usr/local/lib/python3.6/dist-packages (from sofasonix) (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from sofasonix) (1.18.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from sofasonix) (1.0.5)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.6/dist-packages (from netCDF4->sofasonix) (1.2.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->sofasonix) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->sofasonix) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->sofasonix) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1oQNCFx_QIL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from SOFASonix import SOFAFile\n",
        "import scipy.io.wavfile as wav\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsdGpuMT_FAg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "outputId": "ee6ff81a-1a45-41cc-a3f5-7d36ab725b0a"
      },
      "source": [
        "# replace with your path!\n",
        "loadsofa = SOFAFile.load('/content/drive/My Drive/directional_sound/HRIR_FULL2DEG.sofa')\n",
        "data = loadsofa.data_ir\n",
        "direction = loadsofa.SourcePosition\n",
        "direction = direction[:,0:2] # the first two colums are azimuth and elevation angles in degree\n",
        "sr = int(loadsofa.Data_SamplingRate[0]) # sampling_rate in Hz\n",
        "#loadsofa.view() # if interested, you can explore the whole dataset\n",
        "\n",
        "## create noise signal\n",
        "duration = 0.5 #seconds\n",
        "sample_n = int(duration*sr)\n",
        "noise = np.random.uniform(-1,1,sample_n)\n",
        "\n",
        "## create speech signal\n",
        "# You can take the 'hallo2.wav' file from the repository or record your own voice e.g. with Audacity and sampling rate of 48kHz\n",
        "load_speech = wav.read('/content/drive/My Drive/directional_sound/hallo2.wav')\n",
        "speech = load_speech[1]\n",
        "sampling_rate = load_speech[0]\n",
        "if sampling_rate != sr:\n",
        "  print('Warning: sampling_rate != sr')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting dimension 'r' from parameter 'ReceiverPosition'\n",
            "Setting dimension 'e' from parameter 'EmitterPosition'\n",
            "Setting dimension 'm' from parameter 'Data.IR'\n",
            "Setting dimension 'n' from parameter 'Data.IR'\n",
            "Inserting foreign parameter: 'GLOBAL:Author'\n",
            "Inserting foreign parameter: 'GLOBAL:ListenerDescription'\n",
            "Inserting foreign parameter: 'GLOBAL:ReceiverDescription'\n",
            "Inserting foreign parameter: 'GLOBAL:SourceDescription'\n",
            "Inserting foreign parameter: 'GLOBAL:RoomDescription'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xcp1W_Huo0w4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_hrir(az_wish, el_wish):\n",
        "  m_altered = np.abs(direction[:,0]- az_wish) + np.abs(direction[:,1]- el_wish)\n",
        "  m_min = np.amin(m_altered, axis=0)\n",
        "  i_row = np.argwhere(m_altered == m_min)[0][0]\n",
        "  return data[i_row][0], data[i_row][1], i_row"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCW-ZDzHBax6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_stereo(signal, az_wish, el_wish):\n",
        "  '''\n",
        "    signal:  numpy 1D array, e.g. signal=noise or signal=speech\n",
        "    az_wish: azimuth angle in degree at which sound should be virtually placed\n",
        "    el_wish: elevation angle in degree at which sound should be virtually placed\n",
        "  '''\n",
        "  hrir_l, hrir_r, i_row = get_hrir(az_wish, el_wish)\n",
        "  left = np.convolve(signal, hrir_l, mode='valid') # 'valid': avoid boundary effects; The convolution product is only given for points where the signals overlap completely\n",
        "  right = np.convolve(signal, hrir_r, mode='valid')\n",
        "  audio = np.hstack((left.reshape(-1,1), right.reshape(-1,1)))\n",
        "  scaled = np.int16(audio/np.max(np.abs(audio)) * 32767)\n",
        "  file_name = 'stereo['+str(direction[i_row][0].round(1))+', '+str(direction[i_row][1].round(1))+'].wav'\n",
        "  wav.write('/content/drive/My Drive/directional_sound/'+file_name, sr, scaled)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcwS-Edk_jo7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# az (azimuth) is the angle lying in the horizontal plane. It goes from 0° - nose direction, to 90° - left ear, to 180° - back, to 270° - right ear, and again to 360° - nose direction\n",
        "# el (elevation) is the angle lying in the vertical plane. It goes from -88° - down, to 88° - up.\n",
        "get_stereo(signal=speech, az_wish=90, el_wish=0)\n",
        "# You have to use ear phones! Loudspeaker will not make the illusion of sound coming from a certain direction."
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_70zIysLDB1z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_roundabout(signal, az_begin, az_end, step_size, el=0):\n",
        "  '''\n",
        "    signal:   numpy 1D array, e.g. signal=noise or signal=speech\n",
        "    az_begin: azimuth angle in degree at which the roundabout starts\n",
        "    az_end:   azimuth angle in degree at which the roundabout ends\n",
        "    step_size:azimuth angle step in degree\n",
        "    el:       elevation in degree at which the sound travels horizontally around the head\n",
        "  '''\n",
        "  hrir_l, hrir_r, i_row = get_hrir(0, el_wish=0)\n",
        "  left = np.convolve(signal, hrir_l, mode='valid')\n",
        "  right = np.convolve(signal, hrir_r, mode='valid')\n",
        "  audio = np.hstack((left.reshape(-1,1),right.reshape(-1,1)))\n",
        "  print('Simulated alzimuth angles: ', np.arange(az_begin, az_end+1, step_size))\n",
        "  for az_wish in np.arange(az_begin, az_end+1, step_size):\n",
        "    hrir_l, hrir_r, i_row = get_hrir(az_wish, el_wish=el)\n",
        "    left = np.convolve(signal, hrir_l, mode='valid')\n",
        "    right = np.convolve(signal, hrir_r, mode='valid')\n",
        "    audio_n = np.hstack((left.reshape(-1,1),right.reshape(-1,1)))\n",
        "    audio = np.vstack((audio,audio_n))\n",
        "  scaled = np.int16(audio/np.max(np.abs(audio)) * 32767)\n",
        "  file_name = 'new_audio_roundabout_hallo.wav'\n",
        "  wav.write('/content/drive/My Drive/directional_sound/'+file_name, sr, scaled)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9438NqOwChoB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f180fe39-702b-494f-ab28-c5a3abac19ce"
      },
      "source": [
        "get_roundabout(signal=speech, az_begin=0, az_end=360, step_size=45, el=0)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Simulated alzimuth angles:  [  0  45  90 135 180 225 270 315 360]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}